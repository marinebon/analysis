---
title: "rvc_analysis"
author: "Ben Best"
date: "January 18, 2017"
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(raster)
library(sp)
library(leaflet)
library(vegan)
select = dplyr::select
```

## Introduction

Already fetched RVC data from ERDDAP server in erddap_rvc.Rmd for 1999 - 2014.

- Lefcheck (2015) [The use of functional traits to elucidate
the causes and consequences of biological diversity](http://www.vims.edu/library/Theses/Lefcheck15.pdf)
- Lefcheck (2014) [Dimensions of biodiversity in Chesapeake Bay demersal fishes: patterns and drivers through space and time](http://onlinelibrary.wiley.com/doi/10.1890/ES13-00284.1/abstract) with supplemental [R script](https://figshare.com/articles/Supplement_1_R_script_containing_all_data_analyses_and_functional_phylogenetic_and_taxonomic_trees_in_Newick_format_/3563847)

```{r subset, eval=T}
use_subset = T
rvc_rds = 'data/erddap_Florida-Keys-Reef-Visual-Census.rds'
#rds_d_s = 'data/erddap_Florida-Keys-Reef-Visual-Census_subset.rds'
rvc_eff_csv = 'data/rvc_eff.csv'
rvc_obs_csv = 'data/rvc_obs.csv'

#if (!file.exists(rvc_obs_csv)){
  rvc = read_rds(rvc_rds)
    
  # # create effort csv
  # rvc %>%
  #   group_by(eventDate, mapGridNumber, primarySamplingUnit) %>%
  #   summarize(
  #     n_stations = length(unique(station_nr))) %>%
  #   write_csv(rvc_eff_csv)
  
  # summarize individual species counts to PSU
  rvc_psu = rvc %>%
    select(datasetID, eventDate, mapGridNumber, primarySamplingUnit, station_nr, scientificName, quantificationValue) %>%
    filter(!is.na(station_nr)) %>%
    group_by(datasetID, eventDate, mapGridNumber, primarySamplingUnit, scientificName) %>%
    summarise(
      q = sum(quantificationValue, na.rm=T) / length(unique(station_nr))) %>%
    filter(q > 0, !is.na(q)) # filter: NA, 0's
  
  # mapgrid locations
  rvc_mg_loc = rvc %>%
    group_by(datasetID, mapGridNumber) %>% # 200m x 200m
    summarise(
      latitude = mean(latitude, na.rm=T), 
      longitude = mean(longitude, na.rm=T))

  # summarize to mapgrid locations
  rvc_mg = rvc_psu %>%
    left_join(rvc_mg_loc, by=c('datasetID','mapGridNumber')) %>%
    mutate(
      year = year(eventDate)) %>%
    group_by(year, datasetID,  mapGridNumber, scientificName) %>%
    summarize(
      q_mean = mean(q))

  # summarize by species
  # rvc_mg %>%
  #   group_by(scientificName, year) %>%
  #   summarise(
  #     mg_q_var  = var(q_mean),
  #     mg_q_mean = mean(q_mean)) %>%
  #   ungroup()
  
  # vegan prep
  rvc_mg_wide = rvc_mg %>%
    ungroup() %>%
    spread(scientificName, q_mean, fill=0)

  rvc_mg_eff_simpson = 1/(1-diversity(rvc_mg_wide %>% select(-year, -mapGridNumber), index='simpson'))

  esimp_d = rvc_mg_wide %>%
    select(year, datasetID, mapGridNumber) %>%
    mutate(
      eff_simpson = rvc_mg_eff_simpson) %>%
    left_join(
      rvc_mg_loc,
      by='mapGridNumber')
  
  esimp_pts = esimp_d
  coordinates(esimp_pts) = ~longitude+latitude
  
  # plot simpson for one year
  spplot(esimp_pts %>% subset(year==1999), zcol='eff_simpson')
  
  # interactive plot
  pal = colorNumeric('Spectral', esimp_pts@data$eff_simpson)
  
  esimp_pts %>%
    subset(year==2000) %>%
    leaflet() %>% 
      addProviderTiles('Esri.OceanBasemap') %>%
      addCircleMarkers(
        radius = 10,
        color = ~pal(eff_simpson),
        stroke = FALSE, fillOpacity = 0.5)
  
  # rvc_mg_wide %>%
  #   select(year, mapGridNumber) %>%
  #   mutate(
  #     eff_simpson = rvc_mg_eff_simpson) %>%
  #   left_join(
  #     rvc_mg_loc,
  #     by='mapGridNumber')

  # columns ignored (for now):
  # basisOfRecord,bottomType,class,country,datasetID,datasetName,depth,dynamicProperties,eventDateRemarks,eventDateTimeZone,family,genus,geodeticDatum,habitat,habitat_cd,higherInstitutionCode,institutionCode,kingdom,latitude,locality,longitude,mapNumber,materialSampleID,maximumDepthInMeters,minimumDepthInMeters,observedMeanLengthInCm,order,ownerInstitutionCode,phylum,protection,quantificationMethod,quantificationName,quantificationStatus,quantificationUnit,,recordedBy,region,sampleRadiusInMeters,Samples,scientificNameAuthorship,scientificNameIDITIS,scientificNameIDWoRMS,species_cd,species_nr,specificEpithet,stateProvince,subregion_nr,taxonRank,time,timeUncertainty,underwaterVisibilityInMeters,vernacularName,verticalDatum,waterBody,waterTemperatureInCelsius,zone_nr
  
# } else {
#   
#   # read csv's for effort & observation
#   rvc_eff = read_csv(rvc_eff_csv)
#   rvc_obs = read_csv(rvc_obs_csv)
# }

  
# rvc_obs %>%
#   left_join(
#     rvc_eff,
#     by=c('eventDate','mapGridNumber','primarySamplingUnit')) %>%
#   group_by(eventDate, mapGridNumber, primarySamplingUnit, scientificName) %>%
#     summarize(
#       sp_density = length(station_nr))
# 
#   
# if (use_subset){
#   if (!file.exists(rds_d_s)){
#     
#     # subset d for quick coding
#     read_rds(rds_d) %>%
#       mutate(
#         year = year(eventDate)) %>%
#       filter(
#         year %in% sort(unique(year))[1:3],                                   # first 3 years
#         primarySamplingUnit %in% sort(unique(primarySamplingUnit))[1:3]) %>% # first 3 PSUs
#     write_rds(rds_d_s)
#     
#   }
#   # read d_s, subset dataset
#   d = read_rds(rds_d_s)
# } else {
#   # read rds, full dataset
#   d = read_rds(rds_d)
# }
```

```{r analysis old, eval=F, echo=F}

d %>%
  mutate(
    year = year(eventDate)) %>%
  group_by(primarySamplingUnit, year) %>% # TODO: group_by(..., MPA)
  # confirm randomly stratified, so each primarySamplingUnit has one date
  # summarize(
  #   n_dates = length(unique(eventDate))) %>%
  # select(primarySamplingUnit, year, n_dates)
  select(primarySamplingUnit, year, station_nr, eventDate) %>%
  arrange(primarySamplingUnit, year, eventDate, station_nr) %>%
  View()
  summarize(
    
    # n_psu = length(unique(primarySamplingUnit))) %>%
    # select(year, n_psu) %>%
    # arrange(n_psu)

   n_station = length(unique(station_nr))) %>% #station_nr is station number? 
    select(year, n_station) %>%
    arrange(n_station)

#find if any unique psu has all zeros for 
  filter(quantificationValue > 0, !is.na(quantificationValue)) %>% # subset: 11,011 -> 1,529
  dim()

```

```{r functional diversity} 

#read in species list 
spname= readr::read_csv(species_code_species_common_names.rdm)
#read in trait*species dataframe 
sptrait= readr::read_csv(species_trait_matrix.csv)
#read in species*community relative abundance dataframe 

#compute relative abundance of each species in each year and community
#remove 'sp.' in abundance dataframe - identified to family 
#substitute scientific name with species common name 

#arrange alphabetically 

#match species in trait dataframe with species in abundance dataframe 

#compute Gowers distance correcting with Podani for ordered traits 
traits.dist=gowdis(traits,ord="podani")

#Because values of Rao's Q can be maximized when fewer than the max number of functional types are present unless distances are ultramtetric ---- Clustering method to produce ultrametric dendrogram 

#to account for sensitivity in clustering use multiple algorithms  (Mouchet et al., 2008) 
tree_methods = c("single","complete","average","mcquitty","ward")
trees=lapply(tree_methods,function(i) hclust(traits.dist,method=i))
par(mfrow=c(3,2))
for(i in 1:length(trees)) {plot(trees[[i]])}

#convert trees to ultrametric
trees.ultra=lapply(trees,function(i) cl_ultrametric(as.hclust(i)))

#Plot each tree
par(mfrow=c(3,2))
for (i in 1:length(trees.ultra)) {plot(trees.ultra[[i]])}

#Build the consensus tree (Mouchet et al 2008 Oikos)
ensemble.trees=cl_ensemble(list=trees)
class(ensemble.trees)
consensus.tree=cl_consensus(ensemble.trees) 
#plot(consensus.tree)

#Calculate dissimilarity values for each tree using 2-norm (Merigot et al 2010 Ecology) to determine which tree best preserves orignial distances
all.trees=c(trees.ultra,consensus.tree[1])
names(all.trees)=c(tree_methods,"consensus")
(trees.dissim=lapply(all.trees,function(i) cl_dissimilarity(i,traits.dist,method="spectral")))

#Identify best tree and isolate
trees.dissim2=do.call(rbind,trees.dissim)
min.tree=which.min(trees.dissim2)
names(all.trees)[min.tree]
func.dist=all.trees[names(all.trees)==names(all.trees)[min.tree]][[1]]

#Confirm lowest 2-norm value
cl_dissimilarity(func.dist,traits.dist,method="spectral")

#Scale by the max value so that all values are between 0-1 (clue package)
func.dist=func.dist/max(func.dist)
#Plot the best tree
# par(mfrow=c(1,1))
# par(mar=c(3,1,0,16))
# plot(func.dist,horiz=TRUE)
#Save plot: 10" x 15"

#Write newick tree
write.tree(as.phylo(as.hclust(func.dist)),"Functional dendrogram")

#calculate effective Rao's Q 
#Calculate alpha diversity
# TODO: change below inputs to just relative abundance 
alphadiv.list=lapply(list(catch_abund,catch_biomass,catch_pres.abs),
 function(i) {
   #Extract community matrix from object in list
   mat=i[,c(1,18:(ncol(i)-1))]
   rownames(mat)=mat[,1]; mat=mat[,-1]
   #Calculate relative values for community matrix
   rel.mat=mat/apply(mat,1,sum)
   #Compute functional diversity 
   func.div=1/(1-apply(rel.mat,1,function(x) t(x) %*% as.matrix(func.dist) %*% x))
 }

## readr::read_csv() # keeps strings as character, vs evil factors. yay! from readr
# utils::read.csv() # evil! base read of csv
sp_traits = traits %>%
  as_tibble() %>%
  select(-c(1:3)) %>%      # remove extra columns
  arrange(Common_name) %>% # arrange alphabetically by species
  filter(!Common_name == 'Na#') %>%
  mutate( 
    # factors are EVIL!
    Common_name = tolower(as.character(Common_name)),
    # change misclassified categorical traits to numeric 
    Maxlength     = as.numeric(as.character(Maxlength)),
    Trophic_level = as.numeric(as.character(Trophic_level)),
    # ordinal traits
    Complexity   = ordered(
      Complexity, levels=c("Low","Medium","High")),
      Gregariousness = ordered(Gregariousness, levels=c("1","2","3"))) %>%
  as.data.frame()

# conform to: species x traits
rownames(sp_traits) = sp_traits$Common_name
sp_traits = sp_traits %>% select(-Common_name)
head(sp_traits)

sp_sr_ra$data_wide[[1]]


#### OLD (Jan 18)
#Calculate Gower distances
traits.dist = gowdis(traits, ord="podani")

#Functional Diversity
sp_sr_ra %>%
  mutate(
    fd = map(data_wide, dbFD)
  )

# remove species rows in traits without abundances
sp_traits = sp_traits[rownames(sp_traits) %in% colnames(sp_sr_ra$data_wide[[1]]),]

traits_dist = gowdis(sp_traits, ord="podani")

dim(sp_traits)
dim(sp_sr_ra$data_wide[[1]])

#functional_div = dbFD(sp_traits, sp_sr_ra$data_wide[[1]])
#functional_div = dbFD(traits_dist, sp_sr_ra$data_wide[[1]])
# worked w/out factors...
functional_div = dbFD(
  sp_traits %>%
    select(Maxlength, Trophic_level), 
  sp_sr_ra$data_wide[[1]])

# didn't work: Species x species distance matrix was still is not Euclidean after 'sqrt' correction. Use another correction method.
# functional_div = dbFD(
#   sp_traits %>%
#     select(Maxlength, Trophic_level, Water_column), 
#   sp_sr_ra$data_wide[[1]])

# didn't work: Species x species distance matrix was still is not Euclidean after 'sqrt' correction. Use another correction method.
traits_dist = gowdis(
  sp_traits %>%
    select(Maxlength, Trophic_level, Water_column), ord="podani",)

functional_div = dbFD(traits_dist, sp_sr_ra$data_wide[[1]],corr = 'cailliez', calc.FRic= F, calc.FGR=F, calc.CWM=F )

```

```{r correlation}

#Test significance of Spearman rank correlations (H0 that rho = 0)
do.call(rbind,lapply(list("richness","evenness","simpson","shannon", "func.div"),function(j) {
  do.call(rbind,lapply(rev(list("richness","evenness","simpson","shannon","func.div")),function(k) {
    data.frame(title=paste(j,k,sep="~"),
               correlation=cor.test(alphadiv.list[[2]][,j],alphadiv.list[[2]][,k])$estimate,
               p.value=cor.test(alphadiv.list[[2]][,j],alphadiv.list[[2]][,k])$p.value) } ) ) } ) ) 


```

## TODO

- Where's the Dry Tortugas data, eg for 2000?
- check out MPA

## Notes for ERDDAP Correction

- `mapNumber` -> `mpaNumber`
- `Samples`: 361,351 records with Samples # and all other fields are NA or NaN?!
