---
title: "FKNMS_Diversity"
author: "Megan Hepner"
date: "3/10/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

suppressPackageStartupMessages({
  library(tidyverse)
  library(lubridate)
  library(raster)
  library(sp)
  library(leaflet)
  library(scales)
  library(vegan)
  library(rerddap)
  library(DT)
  library(readxl)
  library(stringr)
  library(FD)
  library(clue)
  library(fpc) #Calls: pamk
  library(psych)
  library(raster)
  library(SpadeR) # Sorenzen index (q=0), Horn Index (q=1), Morisita-Horn Index (q=2) 
  library(mgcv) #function GAM 
  library(RColorBrewer) 
  library(tsne)
  library(profvis) #tool to visualize how long each part of your code is taking to run
})

select = dplyr::select
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


The Rao function computes alpha, gamma and beta-components for taxonomic and functional diversity with the Rao quadratic entropy index (Rao 1982)
                                      
## INPUTS:                                                                                 
- abundances: matrix of abundances (c x s) of the s species for the c local communities (subregions)
- dist.func: matrix (s x s), dist object with pairwise functional trait distances between the s species
                                                                                      
## OUTPUTS:                                                                           
- Species Richness, Effective Gini-Simpson Diversity, Effective Functional diversity (FD). 
- beta and gamma diversities are calculated for the whole data set and for each pair of subregoins 

```{r Fetch RVC data}
# csv files to read (since time consuming to create using ERDDAP server calls)
rvc_rds     = 'data/rvc.rds'
rvc_mg_csv  = 'data/rvc_mapgrid_locations.csv'
rvc_spp_csv = 'data/rvc_species_densities.csv'

# assign ERDDAP server URL
eurl = 'http://gcoos4.tamu.edu:8080/erddap/' # search/index.html?page=1&itemsPerPage=1000&searchFor=Florida+Keys+Reef+Fish+Visual+Census

# only load full rvc.rds if need be (since slow)
if (!all(file.exists(c(rvc_mg_csv, rvc_spp_csv)))){
  if (!file.exists(rvc_rds)){
    # create csv files
    
    # search for datasets
    ed_search(query='Reef Visual Census', which='table', url=eurl)
    # TODO / NOTE: ed_search(page_size, page) DO NOT WORK! ACK!
    #ed_search(query='Reef Visual Census', which='table', url=eurl, page=2)
  
    # iterate over years
    all = list()
    
    ids = c(
      # Dry Tortugas
      sprintf('dt%d', c(1999,2000,2004,2006,2008,2010,2012,2014,2016)),
      # Florida Keys
      sprintf('fk%d', 1999:2016)) # diff't method 1994:1998
    
    for (id in ids){ # id = ids[1]
    
      # construct id for dataset
      csv_id   = sprintf('data/%s.csv', id)
      csv_vars = sprintf('data/%s_vars.csv', id)
      cat(sprintf('%s\n', id))
      
      if (!file.exists(csv_vars)){
        # get metadata for dataset
        m = try(info(id, url=eurl), silent = T)
        
        if (class(m) == 'try-error') next
        cat(sprintf('  writing %s\n', csv_vars))
        write_csv(m$variables, csv_vars)
      }
      
      if (!file.exists(csv_id)){
      
        # get metadata for dataset
        m = try(info(id, url=eurl), silent = T)
        
        # if id not found, then move onto next year
        if (class(m) == 'try-error'){
          cat(sprintf('  %s NOT FOUND!\n', id)) # fk2013 NOT FOUND! b/c not there
          next
        } 
        
        # try fetching data, up to 10x
        dap_attempts = 1
        while (dap_attempts < 11){
          
          # load data for individual dataset
          cat('  fetching data', ifelse(dap_attempts > 1, sprintf(': attempt %d\n', dap_attempts), '\n'))
          d_id = try(tabledap(m, fields=m$variables$variable_name, url=eurl), silent = T)
          
          # break out of loop if not giving error
          if (!'try-error' %in% class(d_id)) break
          dap_attempts =+ 1
          cat('  error fetching data\n')
        }
      
        # write to csv
        cat('  writing to csv\n')
        d_id %>%
          tbl_df() %>%
          write_csv(csv_id)
        
      } # end if (!file.exists(csv_id))
    } # end for (yr in 1994:2014)
    
    # bind all csv's into one data frame
    cat("bind all csv's\n")
    d = data_frame()
    for (f in list.files('data','[fk|dt][0-9]+\\.csv', full.names=T)){
      cat(' ', f,'\n')
      d_f = read_csv(
        f, progress=F, trim_ws=T,
        col_types = cols(
          protection = col_character()))
      d = bind_rows(d, d_f)
    }
    
    write_rds(d, rvc_rds) # 4.4 GB
  
    # evaluate commonness of columns
    cat('eval common columns')
    vars = data_frame()
    for (f in list.files('data', '[fk|dt][0-9]+_vars\\.csv', full.names = T)){ # f = list.files('data', 'fk[0-9]+_vars\\.csv', full.names = T)[1]
      cat(f)
  
      vars = bind_rows(
        vars,
        read_csv(f) %>%
          mutate(
            id = str_replace(f, 'data/(.*)_vars\\.csv', '\\1')))
    }
    
    v = vars %>%
      select(variable_name, data_type, id) %>% # drop actual_range
      spread(id, data_type)
    
  
  } else {
    # read data
    d = read_rds(rvc_rds)
  }
  
  # show columns (with same class) not consistently available across all datasets
  summary(d)
  
  d %>%
    head() %>%
    datatable()
}
```

## Summarize by Mapgrid & Species

Next, we aggregate to having average density of species from Secondary Sampling Unit (SSU) and Primary Sampling Unit (PSU) to Map grid (200x200m).

```{r aggregate}
if ( !all(file.exists(c(rvc_mg_csv, rvc_spp_csv))) ){
  
  # read data fetched from erddap (erddap_rvc.Rmd)
  rvc = read_rds(rvc_rds)
    
  # summarize individual species counts to PSU
  rvc_psu = rvc %>%
    select(datasetID, eventDate, mapGridNumber, primarySamplingUnit, station_nr, protection,
           scientificName, quantificationValue) %>% #selecting data columns from rvc
    filter(!is.na(station_nr)) %>% #removing n/a
    group_by(datasetID, eventDate, mapGridNumber, primarySamplingUnit, scientificName) %>% #
    summarise(
      n_stations = length(unique(station_nr)), #numbre of SSU within a PSU
      q_mean_psu = sum(quantificationValue, na.rm=T) / length(unique(station_nr))) %>% #average species count per PSU
    filter(q_mean_psu > 0, !is.na(q_mean_psu)) # filter: NA, 0's
  
  # mapgrid locations
  mg_location = rvc %>%
    group_by(datasetID, mapGridNumber) %>% # 200m x 200m
    summarise(
      latitude = mean(latitude, na.rm=T), 
      longitude = mean(longitude, na.rm=T))

  # summarize species to mapgrid locations
  rvc_spp = rvc_psu %>%
    left_join(mg_location, by=c('datasetID','mapGridNumber')) %>%
    mutate(
      year = year(eventDate)) %>%
    group_by(year, datasetID,  mapGridNumber, scientificName) %>%
    summarize(
      q_mean = mean(q)) %>% #average number of individual species i detected in a mapgrid 
    ungroup()

  # add sampling effort per datasetID (with year) and mapGridNumber by n_stations (secondary sampling units)
  rvc_spp = rvc_spp %>%
    left_join(
      rvc_psu %>%
        group_by(datasetID, eventDate, mapGridNumber, primarySamplingUnit, n_stations) %>%
        summarize(n_spp = n()) %>%
        group_by(datasetID, mapGridNumber) %>%
        summarize(
          n_stations = sum(n_stations)), 
      by = c('datasetID', 'mapGridNumber'))
      
  # write to csv
  write_csv(rvc_mg, rvc_mg_csv)
  write_csv(rvc_spp, rvc_spp_csv)
}

# read in data
rvc_mg = read_csv(rvc_mg_csv)
rvc_spp = read_csv(rvc_spp_csv)

```

## Summarize abundance by Subregion 

 1. Upper Keys 
        + latitude  >24.95
1. Middle Keys
        + latitude  >24.63 and <= 24.95
        + longitude >-81.10 and <= -80.45
1. Lower Keys
        + latitude  >24.55 and <= 24.63
        + longitude >-82.65 and <=-81.10
1. Dry Tortugas 
        + latitude  >24.55 and <= 24.75
        + longitude >-83.5 and <=-82.65

```{r Year and Subregion x Species abundance matrix}

mg_cord_q <- left_join(rvc_mg, rvc_spp) #added lat, long to rvc_spp 

#add column 'subregion' with observations 'UK, MK, LK, DT' 
mg_cord_q = mg_cord_q %>%
  mutate(
    subregion = ifelse (
      latitude > 24.95, 
      "upper_keys",
      ifelse(
        latitude > 24.63 & latitude <= 24.95 & longitude >= -81.10 & longitude <= -80.45,
        "middle_keys",
        ifelse(
          latitude >24.55 & latitude <= 24.63 & longitude >= -82.65 & longitude <= -81.10,
          "lower_keys",
          ifelse(
            latitude >24.55 && latitude <= 24.75 & longitude >= -83.5 && longitude <= -82.65,
            "dry_tortugas")))))
table(mg_cord_q$subregion)

mg_cord_tbl = mg_cord_q %>%
  group_by(year,subregion)  %>%
  nest() #year, subregion, scientificname

mg_p_cord_tbl = mg_cord_q %>%
  group_by(year,subregion, protection)  %>%
  nest() #year, subregion, protection, scientificname

```

```{r Simpson diversity}
#x = mg_cord_tbl$data[[1]]
#spread(x, scientificName, q_mean, fill=0) %>%
 # select(-c(1:6))

map = purrr::map
#map function: the first argument to all map functions is the vector to operate on. The second argument, .f specifies what to do with each piece. map takes a vector and returns a list

#x = mg_cord_tbl$sp_abun_sr[[1]]

x = mean()
apply(x %>% select(-c(1:6)), 2, mean)

mg_cord_tbl =  mg_cord_tbl %>%
  mutate(
    sp_abun_sr = map(
      data, 
      ~ spread(data=.x, scientificName, q_mean, fill=0)), #species*comm abundance matrix 
    effective_simpson_sr = map(
      sp_abun_sr, 
      function(x) 1 / (1 - diversity(x %>% select(-c(1:6)), index='simpson'))),
    # effective simpson averaged across mapgrids
    eff_simpson_avg_mg = map_dbl(
      effective_simpson_sr,
      ~ mean(.x, na.rm=T)),
    # effective simpson using avg species abundance across whole subregion-year
    eff_simpson_avg_mg = map_dbl(
      sp_abun_sr, 
      function(x){
        x = apply(x %>% select(-c(1:6)), 2, mean)
        1 / (1 - diversity(x, index='simpson'))}))
# TODO: Why/how are eff_simpson_avg_mg & eff_simpson_avg_mg different? Which to use?

 # ggplot(data = mg_cord_tbl, mapping = aes(x = year, y = eff_simpson_avg_mg)) + 
 #  geom_point(mapping = aes(color = subregion)) + 
 #  geom_smooth() +
 #  ggtitle("Simpson Diversity in the FKNMS") +
 #  labs(x = "Year", y = "Effective Number of Species", colour = "Subregions") +
 #  scale_color_hue(labels = c("Dry Tortugas", "Lower Keys", "Middle Keys", "Upper Keys"))

# ggplot(data = mg_cord_tbl, mapping = aes(x = year, y = eff_simpson_avg_mg, color = subregion, group = subregion)) + 
#   geom_point() + 
#   geom_line() +
#   facet_wrap(~ subregion, nrow = 2)

# ggplot(data = mg_cord_tbl, mapping = aes(x = year, y = effective_simpson_sr, color = subregion)) + 
#   geom_point() +
#   geom_line()

#ggplot(data = mg_cord_tbl) +
  #geom_smooth(mapping = aes (x = year, y = eff_simpson_avg_mg, linetype = subregion))
  # labs(
  #   x = "Year",
  #   y = "Effective Number of Species",
  #   title = "Simpson Diversity in the FKNMS",
  #   colour = "Subregions"
  # )

# ggplot(data = mg_cord_tbl, mapping = aes(x = year, y = eff_simpson_avg_mg, color = subregion, group = subregion), method = "gam", formula = y ~ s(x)) + 
#   geom_point() +
#   geom_smooth() +
#   ggtitle("Simpson Diversity") +
#   labs(x = "Year", y = "Effective Number of Species", colour = "Subregions") +
#   scale_color_hue(labels = c("Dry Tortugas", "Lower Keys", "Middle Keys", "Upper Keys"))

#plot using loess
qplot(year, eff_simpson_avg_mg, data = mg_cord_tbl, color = subregion, geom = c("point", "smooth"), method = "loess", se = T) +
  facet_grid(subregion ~ .) +
  theme(strip.background = element_blank(), strip.text.y = element_blank()) +
  ggtitle("Simpson Diversity") +
  labs(x = "Year", y = "Effective Number of Species", colour = "Subregion") +
  scale_color_hue(labels = c("Dry Tortugas", "Lower Keys", "Middle Keys", "Upper Keys"))

#plot using lm 
library(splines)
qplot(year, eff_simpson_avg_mg, data = mg_cord_tbl, color = subregion, geom = c("point", "smooth"), method = "lm", formula = y ~ ns(x, 2), se = T) +
  facet_grid(subregion ~ .) +
  theme(strip.background = element_blank(), strip.text.y = element_blank()) +
  ggtitle("Simpson Diversity") +
  labs(x = "Year", y = "Effective Number of Species", colour = "Subregion") +
  scale_color_hue(labels = c("Dry Tortugas", "Lower Keys", "Middle Keys", "Upper Keys"))

#plot using gam
qplot(year, eff_simpson_avg_mg, data = mg_cord_tbl, color = subregion, geom = c("point", "smooth"), method = "gam") +
  facet_grid(subregion ~ .) +
  theme_update(plot.title = element_text(hjust = 0.5)) +
  ggtitle("Simpson Diversity") +
  labs(x = "Year", y = "Effective Number of Species", colour = "Subregion") +
  scale_color_hue(labels = c("Dry Tortugas", "Lower Keys", "Middle Keys", "Upper Keys")) +
  theme(strip.background = element_blank(), strip.text.y = element_blank()) + #removes facet grid title box 
  ylim(5, 25) +
  xlim(1999, 2016)

#TODO: check if individuals that were not detected to species level were removed before computing diversity indices 
  
```

```{r shannon diversity}

x = mean()
apply(x %>% select(-c(1:6)), 2, mean)

mg_cord_tbl =  mg_cord_tbl %>%
  mutate(
    sp_abun_sr = map(
      data, 
      ~ spread(data=.x, scientificName, q_mean, fill=0)), #species*comm abundance matrix 
    effective_shannon_sr = map(
      sp_abun_sr, 
      function(x) exp(diversity(x %>% select(-c(1:6)), index='shannon'))),
    # effective shannon averaged across mapgrids
    eff_shannon_avg_mg = map_dbl(
      effective_shannon_sr,
      ~ mean(.x, na.rm=T)),
    # effective shannon using avg species abundance across whole subregion-year
    eff_shannon_avg_mg = map_dbl(
      sp_abun_sr, 
      function(x){
        x = apply(x %>% select(-c(1:6)), 2, mean)
        exp(diversity(x, index='shannon'))}))

#whole FKNMS Shannon 
 ggplot(data = mg_cord_tbl, mapping = aes(x = year, y = eff_shannon_avg_mg)) + 
  geom_point(mapping = aes(color = subregion)) + 
  geom_smooth() +
  ggtitle("Shannon Diversity in the FKNMS") +
  labs(x = "Year", y = "Effective Number of Species", colour = "Subregions") +
  scale_color_hue(labels = c("Dry Tortugas", "Lower Keys", "Middle Keys", "Upper Keys"))
 
#lm plot 
qplot(year, eff_shannon_avg_mg, data = mg_cord_tbl, color = subregion, geom = c("point", "smooth"), method = "lm") +
  facet_grid(subregion ~ .) +
  theme(strip.background = element_blank(), strip.text.y = element_blank()) +
  ggtitle("Shannon Diversity") +
  labs(x = "Year", y = "Effective Number of Species", colour = "Subregion") +
  scale_color_hue(labels = c("Dry Tortugas", "Lower Keys", "Middle Keys", "Upper Keys")) 
  #scale_x_continuous(breaks = c(2000, 2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016)) +
  #theme(axis.text.x = element_text(angle = 45))

#gam plot
qplot(year, eff_shannon_avg_mg, data = mg_cord_tbl, color = subregion, geom = c("point", "smooth"), method = "gam") +
  facet_grid(subregion ~ .) +
  theme(strip.background = element_blank(), strip.text.y = element_blank()) +
  ggtitle("Shannon Diversity") +
  labs(x = "Year", y = "Effective Number of Species", colour = "Subregion") +
  scale_color_hue(labels = c("Dry Tortugas", "Lower Keys", "Middle Keys", "Upper Keys"))
  

```

## Functional distance 
```{r Functional distance matrix}
rvc_grp = read_csv('data/rvc_spp_grouped.csv')

# wide: common_name x traits
d_traits = rvc_grp %>% 
  group_by(
    common_name, maxlength, trophic_level, trophic_group, water_column, diel_activity, substrate_type, complexity, gregariousness) %>%
  summarize(
    n = n()) %>%
  select(-n) %>%
  ungroup() %>%
  mutate(
    # ordinal traits
    complexity = factor(
      complexity, levels=c("Low","Medium","High"), ordered=T)) %>%
  arrange(common_name) %>%
  as.data.frame()

#dim(d_traits) 333, 8 (species*traits)

#d_traits
View(d_traits)

# conform to: species x traits
rownames(d_traits) = d_traits$common_name
d_traits = select(d_traits, -common_name)
head(d_traits)

#Calculate Gower distances
traits.dist=gowdis(d_traits,ord="podani")

#Use clustering method to produce ultrametric dendrogramBecause values of Rao's Q can be maximized when fewer than the max number of functional types are present unless distances are ultramtetric 

#to account for sensitivity in clustering use multiple algorithms  (Mouchet et al., 2008) 
tree_methods = c("single","complete","average","mcquitty","ward.D") #average is best clustering method 
trees=lapply(tree_methods,function(i) hclust(traits.dist, method=i))
#par(mfrow=c(3,2))
#for(i in 1:length(trees)) {plot(trees[[i]])}

#convert trees to ultrametric
trees.ultra=lapply(trees,function(i) cl_ultrametric(as.hclust(i)))

#Plot each tree
par(mfrow=c(3,2))
for (i in 1:length(trees.ultra)) {plot(trees.ultra[[i]])}

#Build the consensus tree (Mouchet et al 2008 Oikos) from package clue 
ensemble.trees=cl_ensemble(list=trees) #list of clusterings 
class(ensemble.trees)
consensus.tree=cl_consensus(ensemble.trees) #synthesizes the information in the elements of a cluster ensemble into a single clustering 
#plot(consensus.tree)

#Calculate dissimilarity values for each tree using 2-norm (Merigot et al 2010 Ecology) to determine which tree best preserves orignial distances
all.trees=c(trees.ultra,consensus.tree[1])
names(all.trees)=c(tree_methods,"consensus")
trees.dissim=lapply(all.trees,function(i) cl_dissimilarity(i,traits.dist,method="spectral")) #spectral norm (2-norm) of the differences of the ultrametrics

#Identify best tree and isolate
trees.dissim2=do.call(rbind,trees.dissim)
min.tree=which.min(trees.dissim2)
names(all.trees)[min.tree]
func.dist=all.trees[names(all.trees)==names(all.trees)[min.tree]][[1]]

#Confirm lowest 2-norm value
cl_dissimilarity(func.dist,traits.dist,method="spectral")

#Scale by the max value so that all values are between 0-1 (clue package)
func.dist=func.dist/max(func.dist)

#Plot the best tree
par(mfrow=c(1,1))
par(mar=c(3,1,0,16))
plot(func.dist,horiz=TRUE)
#Save plot: 10" x 15"

#Write newick tree
write.tree(as.phylo(as.hclust(func.dist)),"data/dendro_functional.nwk")

#Visualize species' differences in multivariate trait space
#Perform k-means clustering with no a priori specification for k
traits.kclus=pamk(traits.dist,krange=2:10)
# #Perform multidimensional scaling on functional dendrogram
traits_nmds=metaMDS(traits.dist,k=traits.kclus$nc,trymax=500)
# #Plot in two dimensions
par(mar=c(4,4,1,1))
ordiplot(traits_nmds,type="n")
#Assign colors to different groups
groups=levels(factor(traits.kclus$pamobject$clustering))
points.symbols=15:16
points.colors=c("firebrick3","cornflowerblue")
for(i in seq_along(groups)) {
   points(traits_nmds$points[traits.kclus$pamobject$clustering==groups[i],],
          pch=points.symbols[i],col=points.colors[i],cex=1.4) }
 ordispider(traits_nmds,factor(traits_kclus$pamobject$clustering),label=F)
 ordihull(traits_nmds,factor(traits.kclus$pamobject$clustering),lty="dotted")
 orditorp(traits_nmds,dis="sites",pcex=0,air=0.5,col="grey10",cex=0.8)
``` 

Trait matrix visualization 
[http://jkunst.com/r/pokemon-visualize-em-all/]
```{r trait visualization}

tsne_fish_traits <- d_traits %>% 
  select(maxlength, trophic_level, trophic_group, water_column, diel_activity,
         substrate_type, complexity, gregariousness) %>%
  map(function(x){
    ifelse(is.na(x), "NA", x)
  }) %>% 
  as.data.frame() %>% 
  tbl_df() %>% 
  model.matrix(~., data = .) %>% 
  as.data.frame() %>% 
  tbl_df() %>% 
  .[-1] %>% 
  tsne(perplexity = 10)

d_traits <- d_traits %>% 
  mutate(x = tsne_fish_traits[, 1],
         y = tsne_fish_traits[, 2])

dfcenters <- d_traits %>% 
  group_by(trophic_group, water_column) %>% 
  summarise(cx = mean(x),
            cy = mean(y),
            sdcx = sd(x),
            sdcy = sd(y))
```

## Compute Simpson and Functional Diversity for Alpha (subregions) and Gamma (FKNMS)

```{r Alpha diversity - Subregion}

# species abudance by subregion 
subregion_abun<-apply(abundances,1,sum)

# species relative abundances by subregion 
subregion_relabun<-abundances/subregion_abun 

# species richness by subregion
subregion_richness<-apply(abundances,1, function(x) {length(which(x>0))} )  

# functional diversity (effective number of species) by subregion
subregion_func_div=1/(1-apply(subregion_relabun, 1, function(x) t(x) %*%  func.dist %*% x))

# Gini-Simpson diversity (effective number of species) by subregion
species.dist=matrix(1,ncol(abundances),ncol(abundances))-diag(rep(1,ncol(abundances))) 
subregion_simpson_div=1/(1-apply(subregion_relabun,1, function(x) t(x) %*% species.dist %*% x))

```

```{r Gamma Diversity - FKNMS}

# species regional abudance 
regional_abun<-apply(abundances,2,sum)

 # regional species richness
regional_richness<-apply(abundances,2,function(x) {length(which(x>0))} ) 

#regional species relative abundance
regional_relabun <- regional_abun/sum(regional_abun)  

# regional functional diversity (effective number of species)
regional.func.div=1/(1-apply(regional_relabun, 1, function(x) t(x) %*%  func.dist %*% x))

# regional Gini-Simpson diversity (effective number of species)
regional.simpson.div=1/(1-apply(regional_relabun,1,function(x) t(x) %*% species.dist %*% x))

```

